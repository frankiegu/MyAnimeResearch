## dataset_system_plan.md可能过工程化
> 难度高，以至于我只实现了很小部分，还没到能上线的程度

提出重构版，dataset_system_planV2：AnimeBangumi_SEG_system

### findpose.ml给了几个设计改进
1. 验证码系统 - 不同于booru, trace.moe, animeloop.org 系统，让普通用户查询系统时参与标注（对于画师相关人完全开放权限）

2. 用户主动筛选 - **对于shot切割等预处理是不必要的**

### 众包系统设计survey后的见解
采集，筛选，标注：众包系统是异步流水线（
> 索引数据库<->任务数据集

采集&二次采集（索引数据库）：
设计进度数据库，从原始数据中（如动画）主动采集：程序等时距离采样图像，用户在 帧-帧【发现更多】，重复
> 直接一个视频一个文件夹，shot都放文件夹里(hashed list)，命名即是 原始视频的时间点hash
二次采集：这三步如果在具体任务上划分能做更多（建立更多子_任务_hash 文件夹）（比如人体之后就是bone或者脸）

清洗（新建任务domain-task）：
> 对raw进行采集时，时间点,hash筛选

筛选（从索引数据库拉取）：
用户筛选是否为能对其【xx 任务下】有效标注

标注（从任务数据集拉取）：
（视频的时间连续性）连续片段【下一帧】，另一个片段【下一张】

### 任务&数据集设计
（分割）【人物的 实例分割】- 提供 半身，全身，遮挡%，这样的实例笔刷

（分类）【场景的 理解】- 关键点标注(keypoint is all you need.md)，超像素标注（part）

### 模型&工程设计
彻底抛弃研究模型设计相关
（condinst在动漫seg上的强大能力让我意识到，动漫图像也是常规图像，找一个看起来不错的SOTA，然后迁移学习is all we needed）

抛弃对视频处理的问题（视频动作检测还不成熟，3DCNN完全不能用...）

开始对动漫图像增强方面的研究（randaug，遮挡）
