工程目标类似DAVIS Challenge，summe，tvsum，THUMOS
https://davischallenge.org
http://cvlab.hanyang.ac.kr/coview2019/
https://www.crcv.ucf.edu/THUMOS14/download.html

[gwern works (danbooru2019 etc.)](https://www.gwern.net/Crops#danbooru2019-portraits)

充分利用资源与设计数据集，部分思想：

不同于简单bbox标注头像这种，而是片段（例如sakugabooru）
然后用于 视频摘要，视频理解，视频压缩，视频风格迁移 等任务
> video summation, video understanding, video compress, video stylization

例如danbooru众包的方式来标注，制作出真。动画数据集
制作各种video related任务，提出的SOTA模型上跑compare，benchmark之类的

### 提供众包数据库
（片源自己下，不需要像sakugabooru一样带视频，用提供的标注系统 来标注与提交贡献）
github开不同文件夹，分task，动画全名（索引 等meta data）
> 元信息：动画公司，导演，分镜演出作监
提供pair文件，但不提供动画文件（bt下载bd，或提供时轴校正补丁）

视频摘要（片段，很明显的镜头切换）（关键帧，角色动作）【短时中割，上色模型】
> 我认为：可以避免冗余标注
> 关键帧片段，如果能实现短时中割
> 就不需要每帧都标，直接整合到原分割模型，得到带时序的分割模型
> 再将其整合进，语言模型（词模型，上下文），应用条件生成的对抗训练，就能生成有意义的分镜片段

视频理解（分镜是片段集合，分镜语义）（摄影技法，分镜语义，角色行为等等）
音频理解（补丁包，提供音频，字幕理解数据集（效果音，角色对话，背景音乐）

未来可以考虑【**多模态理解，参考deepmind的[《Look, Listen and Learn》](https://arxiv.org/abs/1705.08168)&[《Objects that Sound》](https://arxiv.org/abs/1712.06651)**】

从摘要片段抽取关键帧，实例分割，多标签类别（场景，角色上下文相关等等）【静态图像分割，中割实验集】

其次，对画质，有无字幕的要求
也不是很高，直接就能标
只要不是修正或剪辑，tv版 带提供（时轴校正补丁可以考虑）

### 在线提交系统
就可以开发，未来考虑 对接版权流，视频流的等在线标注插件
不仅限以上任务，提供这样的一个task related数据库，将对动画在深度学习的研究产生重大影响

**反正也没啥版权问题，但我还是附一下**
> 关于收集动画，插画，漫画，等等进行机器学习研究的法律，版权问题？
> 除生成模型以外，无任何问题，（不限于“非商业用途”），收集动漫数据对第三方进行培训并发布经过培训的模型是安全的。

> 从第三方的原始数据创建数据库，通过对数据库进行标签处理等来创建学习数据集并提供和出售数据集的行为 - OK（分类模型，检测模型等）
> 用第三方的学习数据集执行机器学习以生成训练模型并提供和出售训练模型的行为 - NG

> 日本改正著作権法「著作権法４７条の７」
> 進化する機械学習パラダイス ～改正著作権法が日本のAI開発をさらに加速する～
> 機械学習に使うデータセットの著作権について
