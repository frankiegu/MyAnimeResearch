12:08:53
github0000 2021/1/26/周二 12:08:53
话说插画逆向，真的可行？
艾梦 2021/1/26/周二 12:09:15

艾梦 2021/1/26/周二 12:10:08
怎么个逆向法
艾梦 2021/1/26/周二 12:10:21
把颜色逐步擦除？

你撤回了一条消息

github0000 2021/1/26/周二 12:11:16
靠白盒建模一个公式，逆出线稿与上色
艾梦 2021/1/26/周二 12:12:05
应该能，但上色步骤应该跟人类的很不一样
艾梦 2021/1/26/周二 12:12:10

12:13:39
github0000 2021/1/26/周二 12:13:39
不是一个公式哪能

github0000 2021/1/26/周二 12:13:50
这肯定是系统的一部分表现
艾梦 2021/1/26/周二 12:14:17
一个非常复杂的公式
艾梦 2021/1/26/周二 12:14:27
（不是

github0000 2021/1/26/周二 12:14:34
你无法兼容各种图像

github0000 2021/1/26/周二 12:14:54
靠cnn backbone就变成特征容量的问题
艾梦 2021/1/26/周二 12:15:00
我以为你的一个公式就是一个系统
艾梦 2021/1/26/周二 12:15:03


github0000 2021/1/26/周二 12:15:18
传统处理图像又对数据眀感
12:16:49
github0000 2021/1/26/周二 12:16:49
你可以类比：edge，node是network一部分

github0000 2021/1/26/周二 12:17:43
公式？就是那些part
至少你必须运行整个系统才能得到那些part之间的关系（也就是公式）
12:19:03
github0000 2021/1/26/周二 12:19:03
建模这个系统肯定靠不了白盒
12:21:52
github0000 2021/1/26/周二 12:21:52
话说还有谁研究anime相关啊

github0000 2021/1/26/周二 12:22:17
我感觉自己已经不能再往前走了

github0000 2021/1/26/周二 12:22:40
给我看点新玩意
12:24:25
github0000 2021/1/26/周二 12:24:25
再来说研究方向

github0000 2021/1/26/周二 12:25:35
ANN实现了可分感知，MLP实现了基础感知，DNN实现了面向任务的感知
12:26:41
github0000 2021/1/26/周二 12:26:41
下一步应该咋感知？
通用感知

github0000 2021/1/26/周二 12:27:06
通用感知需要是一切黑盒建模的基础
艾梦 2021/1/26/周二 12:27:19

艾梦 2021/1/26/周二 12:27:25
没有人了吗

github0000 2021/1/26/周二 12:27:37
可咋做呢？
mini-task？

github0000 2021/1/26/周二 12:27:43
没有人了

github0000 2021/1/26/周二 12:27:57
谷歌alert也不给我新玩意了
12:29:00
github0000 2021/1/26/周二 12:29:00
gwern的群我也不氵了
艾梦 2021/1/26/周二 12:29:04

艾梦 2021/1/26/周二 12:29:13
我也没咋水

github0000 2021/1/26/周二 12:29:26
他们似乎已经彻底走完anime的路

github0000 2021/1/26/周二 12:29:36
仅随机生成
少冰走甜 2021/1/26/周二 12:29:51
/摸鱼/摸鱼/摸鱼

github0000 2021/1/26/周二 12:29:56
什么都干不了他们不明白吗？
艾梦 2021/1/26/周二 12:30:12
stylegan2可以条件生成呀
艾梦 2021/1/26/周二 12:30:23
配合pSp可以搞线稿上色

github0000 2021/1/26/周二 12:30:41
为什么还天天clip，vit，SG2

github0000 2021/1/26/周二 12:30:50
怎么个能法
12:31:24
github0000 2021/1/26/周二 12:31:24
不能条件因为效果太差不是sg-animeface试过么

github0000 2021/1/26/周二 12:31:34
你不是玩过那个waifu-spam
艾梦 2021/1/26/周二 12:31:57


github0000 2021/1/26/周二 12:32:12
你可以硬train，但没用，效果太差浪费$吧

github0000 2021/1/26/周二 12:33:21
他们只有图像标签，这做cond不可能好的
12:33:39
艾梦 2021/1/26/周二 12:33:39
像投影这样的，不是说条件训练

github0000 2021/1/26/周二 12:33:59
优化那个你也玩了吧

github0000 2021/1/26/周二 12:34:39
1000个sample，score下降
艾梦 2021/1/26/周二 12:35:39

12:35:41
github0000 2021/1/26/周二 12:35:41


github0000 2021/1/26/周二 12:36:25
我不看好
艾梦 2021/1/26/周二 12:37:46
我还是得去试试，不过现在没空去搞，它这个s2模型转权重估计要比原先的麻烦一点

github0000 2021/1/26/周二 12:38:33
是的

github0000 2021/1/26/周二 12:38:43
那个hardcode我看了

github0000 2021/1/26/周二 12:38:46
头大。。
艾梦 2021/1/26/周二 12:39:11


github0000 2021/1/26/周二 12:39:34
权重转换到双桨你准备怎么做

github0000 2021/1/26/周二 12:40:12
你说的投影和那个clip的优化是不是一个方法？

github0000 2021/1/26/周二 12:40:25
草

github0000 2021/1/26/周二 12:40:44
字面意义上你说逆图像啊
艾梦 2021/1/26/周二 12:40:49
对啊

github0000 2021/1/26/周二 12:40:51
那个sg2的效果
艾梦 2021/1/26/周二 12:40:56


github0000 2021/1/26/周二 12:40:58
你真的觉得能逆？

github0000 2021/1/26/周二 12:41:24
他的隐空间至少是biggan的几个数量级大
艾梦 2021/1/26/周二 12:41:41
就是它很大，所以我觉得很困难

github0000 2021/1/26/周二 12:41:49
而且他这个生成的效果

github0000 2021/1/26/周二 12:42:03
恐怕对损失的基础感知都很难
艾梦 2021/1/26/周二 12:42:26
我也是这么觉得的
艾梦 2021/1/26/周二 12:42:45
所以我把试探它的计划放后面了

github0000 2021/1/26/周二 12:42:55
你输进去近似超分过程，然后本质上sg2只“看”到了一些“地狱绘图”

github0000 2021/1/26/周二 12:43:13
恐怕根本没法感知

github0000 2021/1/26/周二 12:44:02
他们训手的那个，增强弄错了

github0000 2021/1/26/周二 12:44:13
也没对齐直接插画等大

github0000 2021/1/26/周二 12:44:28
搞得生成就很多手
艾梦 2021/1/26/周二 12:44:42

艾梦 2021/1/26/周二 12:44:48
真数千手

github0000 2021/1/26/周二 12:44:50
恐怕还有很多域跳跃的问题

github0000 2021/1/26/周二 12:45:11
数据集本来就脏再弄点图像增强

github0000 2021/1/26/周二 12:46:09
不是，他就直接把抠出来的手

github0000 2021/1/26/周二 12:46:19
直接就缩放到跟训练插画等大

github0000 2021/1/26/周二 12:46:47
随机采样出来就很多只有手的
艾梦 2021/1/26/周二 12:46:53
我看到了的
艾梦 2021/1/26/周二 12:47:07
从人变成了一个手
艾梦 2021/1/26/周二 12:47:12


github0000 2021/1/26/周二 12:47:35

